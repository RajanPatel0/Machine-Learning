{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f93be1-55b4-4513-8685-8743307bcc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K Means Algo is a unsupervised ml algorithm used for clustering data into distinct groups it automatically identifies pattern in the data without predefined labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8f8e5ef-4852-4d6d-9e3a-b5b1179e2841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans   #Kmeans class of cluster submodule of sklearn module\n",
    "import warnings  #so as to ignore warnings of few functions\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7539dda0-0906-4ab9-8a30-b0011e147eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Paper</th>\n",
       "      <th>Delicassen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12669</td>\n",
       "      <td>9656</td>\n",
       "      <td>7561</td>\n",
       "      <td>214</td>\n",
       "      <td>2674</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7057</td>\n",
       "      <td>9810</td>\n",
       "      <td>9568</td>\n",
       "      <td>1762</td>\n",
       "      <td>3293</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6353</td>\n",
       "      <td>8808</td>\n",
       "      <td>7684</td>\n",
       "      <td>2405</td>\n",
       "      <td>3516</td>\n",
       "      <td>7844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13265</td>\n",
       "      <td>1196</td>\n",
       "      <td>4221</td>\n",
       "      <td>6404</td>\n",
       "      <td>507</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22615</td>\n",
       "      <td>5410</td>\n",
       "      <td>7198</td>\n",
       "      <td>3915</td>\n",
       "      <td>1777</td>\n",
       "      <td>5185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel  Region  Fresh  Milk  Grocery  Frozen  Paper  Delicassen\n",
       "0        2       3  12669  9656     7561     214   2674        1338\n",
       "1        2       3   7057  9810     9568    1762   3293        1776\n",
       "2        2       3   6353  8808     7684    2405   3516        7844\n",
       "3        1       2  13265  1196     4221    6404    507        1788\n",
       "4        2       3  22615  5410     7198    3915   1777        5185"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('Wholesale data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "593e412b-ac7d-4cd3-9ee2-87d595b648e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Paper</th>\n",
       "      <th>Delicassen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>10304.000000</td>\n",
       "      <td>5743.200000</td>\n",
       "      <td>6397.900000</td>\n",
       "      <td>1904.40000</td>\n",
       "      <td>2138.300000</td>\n",
       "      <td>2528.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.516398</td>\n",
       "      <td>0.823273</td>\n",
       "      <td>5174.539851</td>\n",
       "      <td>3690.536089</td>\n",
       "      <td>2563.511717</td>\n",
       "      <td>1952.15802</td>\n",
       "      <td>1398.017092</td>\n",
       "      <td>2297.36633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5963.000000</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>174.00000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>545.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6529.000000</td>\n",
       "      <td>2375.500000</td>\n",
       "      <td>4728.750000</td>\n",
       "      <td>582.50000</td>\n",
       "      <td>982.000000</td>\n",
       "      <td>1223.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>8496.000000</td>\n",
       "      <td>6593.500000</td>\n",
       "      <td>7086.500000</td>\n",
       "      <td>1381.00000</td>\n",
       "      <td>2225.500000</td>\n",
       "      <td>1738.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12533.250000</td>\n",
       "      <td>8877.000000</td>\n",
       "      <td>7653.250000</td>\n",
       "      <td>2253.75000</td>\n",
       "      <td>3254.750000</td>\n",
       "      <td>2772.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>22615.000000</td>\n",
       "      <td>9810.000000</td>\n",
       "      <td>9568.000000</td>\n",
       "      <td>6404.00000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>7844.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Channel     Region         Fresh         Milk      Grocery  \\\n",
       "count  10.000000  10.000000     10.000000    10.000000    10.000000   \n",
       "mean    1.600000   2.300000  10304.000000  5743.200000  6397.900000   \n",
       "std     0.516398   0.823273   5174.539851  3690.536089  2563.511717   \n",
       "min     1.000000   1.000000   5963.000000   575.000000  2010.000000   \n",
       "25%     1.000000   2.000000   6529.000000  2375.500000  4728.750000   \n",
       "50%     2.000000   2.500000   8496.000000  6593.500000  7086.500000   \n",
       "75%     2.000000   3.000000  12533.250000  8877.000000  7653.250000   \n",
       "max     2.000000   3.000000  22615.000000  9810.000000  9568.000000   \n",
       "\n",
       "           Frozen        Paper  Delicassen  \n",
       "count    10.00000    10.000000    10.00000  \n",
       "mean   1904.40000  2138.300000  2528.50000  \n",
       "std    1952.15802  1398.017092  2297.36633  \n",
       "min     174.00000   300.000000   545.00000  \n",
       "25%     582.50000   982.000000  1223.25000  \n",
       "50%    1381.00000  2225.500000  1738.00000  \n",
       "75%    2253.75000  3254.750000  2772.00000  \n",
       "max    6404.00000  4200.000000  7844.00000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()    #stats of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe51fe16-5d5e-4c1d-9cab-405344733a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.776357e-16</td>\n",
       "      <td>2.775558e-16</td>\n",
       "      <td>-4.440892e-17</td>\n",
       "      <td>7.771561e-17</td>\n",
       "      <td>1.332268e-16</td>\n",
       "      <td>-6.938894e-19</td>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>-5.551115e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.054093e+00</td>\n",
       "      <td>1.054093e+00</td>\n",
       "      <td>1.054093e+00</td>\n",
       "      <td>1.054093e+00</td>\n",
       "      <td>1.054093e+00</td>\n",
       "      <td>1.054093e+00</td>\n",
       "      <td>1.054093e+00</td>\n",
       "      <td>1.054093e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.224745e+00</td>\n",
       "      <td>-1.664479e+00</td>\n",
       "      <td>-8.842942e-01</td>\n",
       "      <td>-1.476144e+00</td>\n",
       "      <td>-1.804264e+00</td>\n",
       "      <td>-9.343515e-01</td>\n",
       "      <td>-1.386062e+00</td>\n",
       "      <td>-9.100824e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.224745e+00</td>\n",
       "      <td>-3.841106e-01</td>\n",
       "      <td>-7.689958e-01</td>\n",
       "      <td>-9.618840e-01</td>\n",
       "      <td>-6.863392e-01</td>\n",
       "      <td>-7.137767e-01</td>\n",
       "      <td>-8.718400e-01</td>\n",
       "      <td>-5.988833e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.164966e-01</td>\n",
       "      <td>2.560738e-01</td>\n",
       "      <td>-3.683032e-01</td>\n",
       "      <td>2.428631e-01</td>\n",
       "      <td>2.831460e-01</td>\n",
       "      <td>-2.826165e-01</td>\n",
       "      <td>6.574803e-02</td>\n",
       "      <td>-3.627023e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.164966e-01</td>\n",
       "      <td>8.962582e-01</td>\n",
       "      <td>4.541149e-01</td>\n",
       "      <td>8.950773e-01</td>\n",
       "      <td>5.161884e-01</td>\n",
       "      <td>1.886360e-01</td>\n",
       "      <td>8.417935e-01</td>\n",
       "      <td>1.117243e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.164966e-01</td>\n",
       "      <td>8.962582e-01</td>\n",
       "      <td>2.507843e+00</td>\n",
       "      <td>1.161561e+00</td>\n",
       "      <td>1.303516e+00</td>\n",
       "      <td>2.429616e+00</td>\n",
       "      <td>1.554504e+00</td>\n",
       "      <td>2.438892e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  1.000000e+01  1.000000e+01  1.000000e+01  1.000000e+01  1.000000e+01   \n",
       "mean  -1.776357e-16  2.775558e-16 -4.440892e-17  7.771561e-17  1.332268e-16   \n",
       "std    1.054093e+00  1.054093e+00  1.054093e+00  1.054093e+00  1.054093e+00   \n",
       "min   -1.224745e+00 -1.664479e+00 -8.842942e-01 -1.476144e+00 -1.804264e+00   \n",
       "25%   -1.224745e+00 -3.841106e-01 -7.689958e-01 -9.618840e-01 -6.863392e-01   \n",
       "50%    8.164966e-01  2.560738e-01 -3.683032e-01  2.428631e-01  2.831460e-01   \n",
       "75%    8.164966e-01  8.962582e-01  4.541149e-01  8.950773e-01  5.161884e-01   \n",
       "max    8.164966e-01  8.962582e-01  2.507843e+00  1.161561e+00  1.303516e+00   \n",
       "\n",
       "                  5             6             7  \n",
       "count  1.000000e+01  1.000000e+01  1.000000e+01  \n",
       "mean  -6.938894e-19 -1.110223e-16 -5.551115e-18  \n",
       "std    1.054093e+00  1.054093e+00  1.054093e+00  \n",
       "min   -9.343515e-01 -1.386062e+00 -9.100824e-01  \n",
       "25%   -7.137767e-01 -8.718400e-01 -5.988833e-01  \n",
       "50%   -2.826165e-01  6.574803e-02 -3.627023e-01  \n",
       "75%    1.886360e-01  8.417935e-01  1.117243e-01  \n",
       "max    2.429616e+00  1.554504e+00  2.438892e+00  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standerdizing the data\n",
    "from sklearn.preprocessing import StandardScaler   #usin StandardScaler class to scale values\n",
    "\n",
    "scaler = StandardScaler()   #initiade that class\n",
    "data_scaled= scaler.fit_transform(data)   #using object/method fit_transform of that StandardScaler class - fit data in singe transform\n",
    "\n",
    "pd.DataFrame(data_scaled).describe()   #converting object data_scaled to dataframe\n",
    "#print(data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a066a4ff-72dc-473b-9874-834047fa6572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KMeans in module sklearn.cluster._kmeans:\n",
      "\n",
      "class KMeans(_BaseKMeans)\n",
      " |  KMeans(n_clusters=8, *, init='k-means++', n_init='auto', max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n",
      " |\n",
      " |  K-Means clustering.\n",
      " |\n",
      " |  Read more in the :ref:`User Guide <k_means>`.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |\n",
      " |  n_clusters : int, default=8\n",
      " |      The number of clusters to form as well as the number of\n",
      " |      centroids to generate.\n",
      " |\n",
      " |      For an example of how to choose an optimal value for `n_clusters` refer to\n",
      " |      :ref:`sphx_glr_auto_examples_cluster_plot_kmeans_silhouette_analysis.py`.\n",
      " |\n",
      " |  init : {'k-means++', 'random'}, callable or array-like of shape             (n_clusters, n_features), default='k-means++'\n",
      " |      Method for initialization:\n",
      " |\n",
      " |      * 'k-means++' : selects initial cluster centroids using sampling             based on an empirical probability distribution of the points'             contribution to the overall inertia. This technique speeds up             convergence. The algorithm implemented is \"greedy k-means++\". It             differs from the vanilla k-means++ by making several trials at             each sampling step and choosing the best centroid among them.\n",
      " |\n",
      " |      * 'random': choose `n_clusters` observations (rows) at random from         data for the initial centroids.\n",
      " |\n",
      " |      * If an array is passed, it should be of shape (n_clusters, n_features)        and gives the initial centers.\n",
      " |\n",
      " |      * If a callable is passed, it should take arguments X, n_clusters and a        random state and return an initialization.\n",
      " |\n",
      " |      For an example of how to use the different `init` strategy, see the example\n",
      " |      entitled :ref:`sphx_glr_auto_examples_cluster_plot_kmeans_digits.py`.\n",
      " |\n",
      " |  n_init : 'auto' or int, default='auto'\n",
      " |      Number of times the k-means algorithm is run with different centroid\n",
      " |      seeds. The final results is the best output of `n_init` consecutive runs\n",
      " |      in terms of inertia. Several runs are recommended for sparse\n",
      " |      high-dimensional problems (see :ref:`kmeans_sparse_high_dim`).\n",
      " |\n",
      " |      When `n_init='auto'`, the number of runs depends on the value of init:\n",
      " |      10 if using `init='random'` or `init` is a callable;\n",
      " |      1 if using `init='k-means++'` or `init` is an array-like.\n",
      " |\n",
      " |      .. versionadded:: 1.2\n",
      " |         Added 'auto' option for `n_init`.\n",
      " |\n",
      " |      .. versionchanged:: 1.4\n",
      " |         Default value for `n_init` changed to `'auto'`.\n",
      " |\n",
      " |  max_iter : int, default=300\n",
      " |      Maximum number of iterations of the k-means algorithm for a\n",
      " |      single run.\n",
      " |\n",
      " |  tol : float, default=1e-4\n",
      " |      Relative tolerance with regards to Frobenius norm of the difference\n",
      " |      in the cluster centers of two consecutive iterations to declare\n",
      " |      convergence.\n",
      " |\n",
      " |  verbose : int, default=0\n",
      " |      Verbosity mode.\n",
      " |\n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Determines random number generation for centroid initialization. Use\n",
      " |      an int to make the randomness deterministic.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |\n",
      " |  copy_x : bool, default=True\n",
      " |      When pre-computing distances it is more numerically accurate to center\n",
      " |      the data first. If copy_x is True (default), then the original data is\n",
      " |      not modified. If False, the original data is modified, and put back\n",
      " |      before the function returns, but small numerical differences may be\n",
      " |      introduced by subtracting and then adding the data mean. Note that if\n",
      " |      the original data is not C-contiguous, a copy will be made even if\n",
      " |      copy_x is False. If the original data is sparse, but not in CSR format,\n",
      " |      a copy will be made even if copy_x is False.\n",
      " |\n",
      " |  algorithm : {\"lloyd\", \"elkan\"}, default=\"lloyd\"\n",
      " |      K-means algorithm to use. The classical EM-style algorithm is `\"lloyd\"`.\n",
      " |      The `\"elkan\"` variation can be more efficient on some datasets with\n",
      " |      well-defined clusters, by using the triangle inequality. However it's\n",
      " |      more memory intensive due to the allocation of an extra array of shape\n",
      " |      `(n_samples, n_clusters)`.\n",
      " |\n",
      " |      .. versionchanged:: 0.18\n",
      " |          Added Elkan algorithm\n",
      " |\n",
      " |      .. versionchanged:: 1.1\n",
      " |          Renamed \"full\" to \"lloyd\", and deprecated \"auto\" and \"full\".\n",
      " |          Changed \"auto\" to use \"lloyd\" instead of \"elkan\".\n",
      " |\n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cluster_centers_ : ndarray of shape (n_clusters, n_features)\n",
      " |      Coordinates of cluster centers. If the algorithm stops before fully\n",
      " |      converging (see ``tol`` and ``max_iter``), these will not be\n",
      " |      consistent with ``labels_``.\n",
      " |\n",
      " |  labels_ : ndarray of shape (n_samples,)\n",
      " |      Labels of each point\n",
      " |\n",
      " |  inertia_ : float\n",
      " |      Sum of squared distances of samples to their closest cluster center,\n",
      " |      weighted by the sample weights if provided.\n",
      " |\n",
      " |  n_iter_ : int\n",
      " |      Number of iterations run.\n",
      " |\n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |\n",
      " |      .. versionadded:: 0.24\n",
      " |\n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |\n",
      " |      .. versionadded:: 1.0\n",
      " |\n",
      " |  See Also\n",
      " |  --------\n",
      " |  MiniBatchKMeans : Alternative online implementation that does incremental\n",
      " |      updates of the centers positions using mini-batches.\n",
      " |      For large scale learning (say n_samples > 10k) MiniBatchKMeans is\n",
      " |      probably much faster than the default batch implementation.\n",
      " |\n",
      " |  Notes\n",
      " |  -----\n",
      " |  The k-means problem is solved using either Lloyd's or Elkan's algorithm.\n",
      " |\n",
      " |  The average complexity is given by O(k n T), where n is the number of\n",
      " |  samples and T is the number of iteration.\n",
      " |\n",
      " |  The worst case complexity is given by O(n^(k+2/p)) with\n",
      " |  n = n_samples, p = n_features.\n",
      " |  Refer to :doi:`\"How slow is the k-means method?\" D. Arthur and S. Vassilvitskii -\n",
      " |  SoCG2006.<10.1145/1137856.1137880>` for more details.\n",
      " |\n",
      " |  In practice, the k-means algorithm is very fast (one of the fastest\n",
      " |  clustering algorithms available), but it falls in local minima. That's why\n",
      " |  it can be useful to restart it several times.\n",
      " |\n",
      " |  If the algorithm stops before fully converging (because of ``tol`` or\n",
      " |  ``max_iter``), ``labels_`` and ``cluster_centers_`` will not be consistent,\n",
      " |  i.e. the ``cluster_centers_`` will not be the means of the points in each\n",
      " |  cluster. Also, the estimator will reassign ``labels_`` after the last\n",
      " |  iteration to make ``labels_`` consistent with ``predict`` on the training\n",
      " |  set.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from sklearn.cluster import KMeans\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[1, 2], [1, 4], [1, 0],\n",
      " |  ...               [10, 2], [10, 4], [10, 0]])\n",
      " |  >>> kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(X)\n",
      " |  >>> kmeans.labels_\n",
      " |  array([1, 1, 1, 0, 0, 0], dtype=int32)\n",
      " |  >>> kmeans.predict([[0, 0], [12, 3]])\n",
      " |  array([1, 0], dtype=int32)\n",
      " |  >>> kmeans.cluster_centers_\n",
      " |  array([[10.,  2.],\n",
      " |         [ 1.,  2.]])\n",
      " |\n",
      " |  For a more detailed example of K-Means using the iris dataset see\n",
      " |  :ref:`sphx_glr_auto_examples_cluster_plot_cluster_iris.py`.\n",
      " |\n",
      " |  For examples of common problems with K-Means and how to address them see\n",
      " |  :ref:`sphx_glr_auto_examples_cluster_plot_kmeans_assumptions.py`.\n",
      " |\n",
      " |  For an example of how to use K-Means to perform color quantization see\n",
      " |  :ref:`sphx_glr_auto_examples_cluster_plot_color_quantization.py`.\n",
      " |\n",
      " |  For a demonstration of how K-Means can be used to cluster text documents see\n",
      " |  :ref:`sphx_glr_auto_examples_text_plot_document_clustering.py`.\n",
      " |\n",
      " |  For a comparison between K-Means and MiniBatchKMeans refer to example\n",
      " |  :ref:`sphx_glr_auto_examples_cluster_plot_mini_batch_kmeans.py`.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      KMeans\n",
      " |      _BaseKMeans\n",
      " |      sklearn.base.ClassNamePrefixFeaturesOutMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.utils._set_output._SetOutputMixin\n",
      " |      sklearn.base.ClusterMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, n_clusters=8, *, init='k-means++', n_init='auto', max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  fit(self, X, y=None, sample_weight=None)\n",
      " |      Compute k-means clustering.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training instances to cluster. It must be noted that the data\n",
      " |          will be converted to C ordering, which will cause a memory\n",
      " |          copy if the given data is not C-contiguous.\n",
      " |          If a sparse matrix is passed, a copy will be made if it's not in\n",
      " |          CSR format.\n",
      " |\n",
      " |      y : Ignored\n",
      " |          Not used, present here for API consistency by convention.\n",
      " |\n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight. `sample_weight` is not used during\n",
      " |          initialization if `init` is a callable or a user provided array.\n",
      " |\n",
      " |          .. versionadded:: 0.20\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |\n",
      " |  set_fit_request(self: sklearn.cluster._kmeans.KMeans, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.cluster._kmeans.KMeans from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |\n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      The options for each parameter are:\n",
      " |\n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |\n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |\n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |\n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |\n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |\n",
      " |      .. versionadded:: 1.3\n",
      " |\n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |\n",
      " |  set_score_request(self: sklearn.cluster._kmeans.KMeans, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.cluster._kmeans.KMeans from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |\n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      The options for each parameter are:\n",
      " |\n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |\n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |\n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |\n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |\n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |\n",
      " |      .. versionadded:: 1.3\n",
      " |\n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseKMeans:\n",
      " |\n",
      " |  fit_predict(self, X, y=None, sample_weight=None)\n",
      " |      Compute cluster centers and predict cluster index for each sample.\n",
      " |\n",
      " |      Convenience method; equivalent to calling fit(X) followed by\n",
      " |      predict(X).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          New data to transform.\n",
      " |\n",
      " |      y : Ignored\n",
      " |          Not used, present here for API consistency by convention.\n",
      " |\n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : ndarray of shape (n_samples,)\n",
      " |          Index of the cluster each sample belongs to.\n",
      " |\n",
      " |  fit_transform(self, X, y=None, sample_weight=None)\n",
      " |      Compute clustering and transform X to cluster-distance space.\n",
      " |\n",
      " |      Equivalent to fit(X).transform(X), but more efficiently implemented.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          New data to transform.\n",
      " |\n",
      " |      y : Ignored\n",
      " |          Not used, present here for API consistency by convention.\n",
      " |\n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray of shape (n_samples, n_clusters)\n",
      " |          X transformed in the new space.\n",
      " |\n",
      " |  predict(self, X)\n",
      " |      Predict the closest cluster each sample in X belongs to.\n",
      " |\n",
      " |      In the vector quantization literature, `cluster_centers_` is called\n",
      " |      the code book and each value returned by `predict` is the index of\n",
      " |      the closest code in the code book.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          New data to predict.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : ndarray of shape (n_samples,)\n",
      " |          Index of the cluster each sample belongs to.\n",
      " |\n",
      " |  score(self, X, y=None, sample_weight=None)\n",
      " |      Opposite of the value of X on the K-means objective.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          New data.\n",
      " |\n",
      " |      y : Ignored\n",
      " |          Not used, present here for API consistency by convention.\n",
      " |\n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Opposite of the value of X on the K-means objective.\n",
      " |\n",
      " |  transform(self, X)\n",
      " |      Transform X to a cluster-distance space.\n",
      " |\n",
      " |      In the new space, each dimension is the distance to the cluster\n",
      " |      centers. Note that even if X is sparse, the array returned by\n",
      " |      `transform` will typically be dense.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          New data to transform.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray of shape (n_samples, n_clusters)\n",
      " |          X transformed in the new space.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassNamePrefixFeaturesOutMixin:\n",
      " |\n",
      " |  get_feature_names_out(self, input_features=None)\n",
      " |      Get output feature names for transformation.\n",
      " |\n",
      " |      The feature names out will prefixed by the lowercased class name. For\n",
      " |      example, if the transformer outputs 3 features, then the feature names\n",
      " |      out are: `[\"class_name0\", \"class_name1\", \"class_name2\"]`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : array-like of str or None, default=None\n",
      " |          Only used to validate feature names with the names seen in `fit`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_names_out : ndarray of str objects\n",
      " |          Transformed feature names.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassNamePrefixFeaturesOutMixin:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |\n",
      " |  set_output(self, *, transform=None)\n",
      " |      Set output container.\n",
      " |\n",
      " |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      " |      for an example on how to use the API.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      " |          Configure output of `transform` and `fit_transform`.\n",
      " |\n",
      " |          - `\"default\"`: Default output format of a transformer\n",
      " |          - `\"pandas\"`: DataFrame output\n",
      " |          - `\"polars\"`: Polars output\n",
      " |          - `None`: Transform configuration is unchanged\n",
      " |\n",
      " |          .. versionadded:: 1.4\n",
      " |              `\"polars\"` option was added.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |\n",
      " |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      " |      This method is called when a class is subclassed.\n",
      " |\n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |\n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  __setstate__(self, state)\n",
      " |\n",
      " |  __sklearn_clone__(self)\n",
      " |\n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |\n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |\n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |\n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |\n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fafb0264-3a3d-475a-8435-cc8155956ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.14587622648762"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2, init='k-means++')   #initialize algo with k means++  && and 2 cluster\n",
    "\n",
    "kmeans.fit(data_scaled)\n",
    "\n",
    "kmeans.inertia_   #attribute of KMeans used to give inertia of the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28b17ad2-a3d6-4854-8f07-3c02184053f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So as to check if it's correct using confusion metrix\n",
    "wcss=[]\n",
    "\n",
    "for cluster in range(1, 11):   #at starting cluster=1 means n_cluster=1\n",
    "    kmeans=KMeans(n_clusters=cluster, init='k-means++')\n",
    "    kmeans.fit(data_scaled)\n",
    "    wcss.append(kmeans.inertia_)   #calculating inertia and append(adding at end of list) that to list wcss\n",
    "    #then so on cluster=2 as ++ , 3,4,5....21 again loop goes for cluster and n_cluster\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(range(1,11), wcss, marker='o')\n",
    "plt.title(\"The Elbow Curve\")\n",
    "plt.xlabel(\"Number Of Cluster\")\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25c45c7e-012b-452a-8b34-7f6e4b3f2f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.896258</td>\n",
       "      <td>0.481768</td>\n",
       "      <td>1.117576</td>\n",
       "      <td>0.478256</td>\n",
       "      <td>-0.912753</td>\n",
       "      <td>0.403913</td>\n",
       "      <td>-0.546233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.896258</td>\n",
       "      <td>-0.661438</td>\n",
       "      <td>1.161561</td>\n",
       "      <td>1.303516</td>\n",
       "      <td>-0.076891</td>\n",
       "      <td>0.870634</td>\n",
       "      <td>-0.345267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.896258</td>\n",
       "      <td>-0.804848</td>\n",
       "      <td>0.875370</td>\n",
       "      <td>0.528833</td>\n",
       "      <td>0.270305</td>\n",
       "      <td>1.038774</td>\n",
       "      <td>2.438892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-0.384111</td>\n",
       "      <td>0.603178</td>\n",
       "      <td>-1.298773</td>\n",
       "      <td>-0.895121</td>\n",
       "      <td>2.429616</td>\n",
       "      <td>-1.229986</td>\n",
       "      <td>-0.339761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.896258</td>\n",
       "      <td>2.507843</td>\n",
       "      <td>-0.095169</td>\n",
       "      <td>0.328994</td>\n",
       "      <td>1.085649</td>\n",
       "      <td>-0.272417</td>\n",
       "      <td>1.218873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.816497  0.896258  0.481768  1.117576  0.478256 -0.912753  0.403913   \n",
       "1  0.816497  0.896258 -0.661438  1.161561  1.303516 -0.076891  0.870634   \n",
       "2  0.816497  0.896258 -0.804848  0.875370  0.528833  0.270305  1.038774   \n",
       "3 -1.224745 -0.384111  0.603178 -1.298773 -0.895121  2.429616 -1.229986   \n",
       "4  0.816497  0.896258  2.507843 -0.095169  0.328994  1.085649 -0.272417   \n",
       "\n",
       "          7  \n",
       "0 -0.546233  \n",
       "1 -0.345267  \n",
       "2  2.438892  \n",
       "3 -0.339761  \n",
       "4  1.218873  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build model with 4 or 5-Cluster\n",
    "\n",
    "kmeans=KMeans(n_clusters=4, init='k-means++')   #here final clusters =4 \n",
    "kmeans.fit(data_scaled)\n",
    "pred=kmeans.predict(data_scaled)  #getting predictions from k-means with predict method on datascaled(No strain ,y train cuzz unsupervised learning) && having no outputs\n",
    "\n",
    "df=pd.DataFrame(data_scaled)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e02af59d-b5b8-4743-bb2a-812493ae2810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.896258</td>\n",
       "      <td>0.481768</td>\n",
       "      <td>1.117576</td>\n",
       "      <td>0.478256</td>\n",
       "      <td>-0.912753</td>\n",
       "      <td>0.403913</td>\n",
       "      <td>-0.546233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.896258</td>\n",
       "      <td>-0.661438</td>\n",
       "      <td>1.161561</td>\n",
       "      <td>1.303516</td>\n",
       "      <td>-0.076891</td>\n",
       "      <td>0.870634</td>\n",
       "      <td>-0.345267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.896258</td>\n",
       "      <td>-0.804848</td>\n",
       "      <td>0.875370</td>\n",
       "      <td>0.528833</td>\n",
       "      <td>0.270305</td>\n",
       "      <td>1.038774</td>\n",
       "      <td>2.438892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-0.384111</td>\n",
       "      <td>0.603178</td>\n",
       "      <td>-1.298773</td>\n",
       "      <td>-0.895121</td>\n",
       "      <td>2.429616</td>\n",
       "      <td>-1.229986</td>\n",
       "      <td>-0.339761</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.896258</td>\n",
       "      <td>2.507843</td>\n",
       "      <td>-0.095169</td>\n",
       "      <td>0.328994</td>\n",
       "      <td>1.085649</td>\n",
       "      <td>-0.272417</td>\n",
       "      <td>1.218873</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-1.664479</td>\n",
       "      <td>-0.181503</td>\n",
       "      <td>-1.476144</td>\n",
       "      <td>-1.804264</td>\n",
       "      <td>-0.934351</td>\n",
       "      <td>-0.876364</td>\n",
       "      <td>-0.616433</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.896258</td>\n",
       "      <td>0.371155</td>\n",
       "      <td>-0.726676</td>\n",
       "      <td>0.237298</td>\n",
       "      <td>-0.769123</td>\n",
       "      <td>0.755273</td>\n",
       "      <td>-0.910082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-1.664479</td>\n",
       "      <td>-0.555103</td>\n",
       "      <td>-1.040287</td>\n",
       "      <td>-0.059993</td>\n",
       "      <td>-0.547738</td>\n",
       "      <td>-0.858268</td>\n",
       "      <td>-0.782070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.816497</td>\n",
       "      <td>-0.384111</td>\n",
       "      <td>-0.884294</td>\n",
       "      <td>0.580895</td>\n",
       "      <td>-1.393073</td>\n",
       "      <td>-0.488342</td>\n",
       "      <td>-1.386062</td>\n",
       "      <td>0.262219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-0.384111</td>\n",
       "      <td>-0.876757</td>\n",
       "      <td>0.901647</td>\n",
       "      <td>1.275555</td>\n",
       "      <td>-0.056372</td>\n",
       "      <td>1.554504</td>\n",
       "      <td>-0.380138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.816497  0.896258  0.481768  1.117576  0.478256 -0.912753  0.403913   \n",
       "1  0.816497  0.896258 -0.661438  1.161561  1.303516 -0.076891  0.870634   \n",
       "2  0.816497  0.896258 -0.804848  0.875370  0.528833  0.270305  1.038774   \n",
       "3 -1.224745 -0.384111  0.603178 -1.298773 -0.895121  2.429616 -1.229986   \n",
       "4  0.816497  0.896258  2.507843 -0.095169  0.328994  1.085649 -0.272417   \n",
       "5 -1.224745 -1.664479 -0.181503 -1.476144 -1.804264 -0.934351 -0.876364   \n",
       "6  0.816497  0.896258  0.371155 -0.726676  0.237298 -0.769123  0.755273   \n",
       "7 -1.224745 -1.664479 -0.555103 -1.040287 -0.059993 -0.547738 -0.858268   \n",
       "8  0.816497 -0.384111 -0.884294  0.580895 -1.393073 -0.488342 -1.386062   \n",
       "9 -1.224745 -0.384111 -0.876757  0.901647  1.275555 -0.056372  1.554504   \n",
       "\n",
       "          7  Cluster  \n",
       "0 -0.546233        1  \n",
       "1 -0.345267        1  \n",
       "2  2.438892        1  \n",
       "3 -0.339761        3  \n",
       "4  1.218873        2  \n",
       "5 -0.616433        0  \n",
       "6 -0.910082        1  \n",
       "7 -0.782070        0  \n",
       "8  0.262219        1  \n",
       "9 -0.380138        1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cluster']=pred     #pred is object that contais predictions\n",
    "df    #give 4th belongs to cluster no. 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1eff6cf7-ec77-4db8-bc69-a9be16eff570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cluster\n",
       "1    6\n",
       "0    2\n",
       "3    1\n",
       "2    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f4058c5-7d6b-4a1f-b34f-8d435c3f98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to take input, standardize it, and predict the cluster\n",
    "def get_cluster_prediction():\n",
    "    #collecting users inputs for each feature\n",
    "    Channel=int(input(\"Enter Channel e.g.(1,2,3..: \"))\n",
    "    Region=int(input(\"Enter Region e.g.(1,2,3..:\"))\n",
    "    Fresh=float(input(\"Enter Annual Spending on Fresh Products:\"))\n",
    "    Milk=float(input(\"Enter Annual Spending on Milk:\"))\n",
    "    Grocery=float(input(\"Enter Annual Spending on Grocery:\"))\n",
    "    Frozen=float(input(\"Enter Annual Spending on Frozen Products:\"))\n",
    "    Detergent_Paper=float(input(\"Enter Annual Spending on Detergent_Paper:\"))\n",
    "    Delicassen=float(input(\"Enter Annual Spending on delicassen: \"))\n",
    "\n",
    "#create a data point with the input values\n",
    "    user_data=np.array([[Channel, Region, Fresh, Milk, Grocery, Frozen, Detergent_Paper, Delicassen]])\n",
    "\n",
    "#standardize the user input using the fitted scaler\n",
    "    cluster= kmeans.predict(user_data)\n",
    "\n",
    "#output\n",
    "    print(f\"The customer belongs to cluster: {cluster[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "edf89604-b377-462e-ba6e-365f843fae1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Channel e.g.(1,2,3..:  1\n",
      "Enter Region e.g.(1,2,3..: 3\n",
      "Enter Annual Spending on Fresh Products: 23456\n",
      "Enter Annual Spending on Milk: 3424\n",
      "Enter Annual Spending on Grocery: 6743\n",
      "Enter Annual Spending on Frozen Products: 785\n",
      "Enter Annual Spending on Detergent_Paper: 356\n",
      "Enter Annual Spending on delicassen:  489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The customer belongs to cluster: 2\n"
     ]
    }
   ],
   "source": [
    "get_cluster_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffeeb5c-3a65-48f3-8e70-21977809effb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
